{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 256\n",
    "image_directory = r'E:/Project/2024 Project/BrainTumor_Lam/datasets/'\n",
    "\n",
    "no_tumor_images = os.listdir(image_directory + 'sort_crop_no/')\n",
    "yes_tumor_images = os.listdir(image_directory + 'sort_crop_yes/')\n",
    "dataset = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in no_tumor_images:\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image = cv2.imread(image_directory + 'sort_crop_no/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        labels.append(0)\n",
    "\n",
    "for image_name in yes_tumor_images:\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image = cv2.imread(image_directory + 'sort_crop_yes/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "x_train = x_train.permute(0, 3, 1, 2) / 255.0 \n",
    "x_test = x_test.permute(0, 3, 1, 2) / 255.0\n",
    "# chuyển tenser đang từ (batch, height, width, channel) sang (batch, channel, height, width) \n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "# TensorDataset nhận các tensor đầu vào và tạo thành một dataset trong đó, mỗi phần tử là một tuple chứa mẫu dữ liệu và nhãn tương ứng\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainTumorNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # 3 channel đầu vào, 32 channel đầu ra, padding = 1 tức là thêm 1 hàng 0 vào 2 bên để giữ nguyên kích thước\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * (INPUT_SIZE // 8) * (INPUT_SIZE // 8), 64) \n",
    "        # INPUT_SIZE // 8 vì sau 3 lớp convolution và 3 lớp pooling, kích thước ảnh giảm đi 8 lần\n",
    "        # 64 là số lượng kênh vào từ lớp tích chập cuối cùng , 64 là số nút đầu ra của lớp fully connected\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        #64 đầu vào và 1 đầu ra\n",
    "        self.dropout = nn.Dropout(0.3)  # Increased dropout rate to 0.3 for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * (INPUT_SIZE // 8) * (INPUT_SIZE // 8))\n",
    "        # view dùng để thay đổi hình dạng của tensor, -1 tức là giữ nguyên số hàng, còn lại là 64 * (INPUT_SIZE // 8) * (INPUT_SIZE // 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrainTumorNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chức Năng Của optimizer.zero_grad()\n",
    "Đặt Lại Gradient:\n",
    "Trong PyTorch, gradient của các tham số mô hình được tính toán và lưu trữ trong đối tượng Tensor khi bạn gọi loss.backward(). Tuy nhiên, các giá trị gradient này sẽ được cộng dồn (accumulated) qua nhiều lần tính toán gradient liên tiếp nếu bạn không đặt lại chúng.\n",
    "optimizer.zero_grad() được sử dụng để đặt lại tất cả các gradient của các tham số mô hình về 0 trước khi tính toán gradient cho lần huấn luyện tiếp theo.\n",
    "Tránh Tích Lũy Gradient:\n",
    "Nếu bạn không gọi zero_grad(), gradient của các tham số sẽ được cộng dồn qua các lần gọi loss.backward(). Điều này có thể dẫn đến các gradient lớn không mong muốn và làm sai lệch quá trình tối ưu hóa.\n",
    "Đặt lại gradient về 0 đảm bảo rằng gradient của mỗi batch được tính toán độc lập với các batch khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\miniconda3\\envs\\brain_tumor_detection\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.6848\n",
      "Validation Loss: 0.6552, Val_Accuracy: 64.65%\n",
      "Epoch [2/30], Loss: 0.5978\n",
      "Validation Loss: 0.5251, Val_Accuracy: 78.14%\n",
      "Epoch [3/30], Loss: 0.4596\n",
      "Validation Loss: 0.4249, Val_Accuracy: 80.47%\n",
      "Epoch [4/30], Loss: 0.3209\n",
      "Validation Loss: 0.3036, Val_Accuracy: 88.60%\n",
      "Epoch [5/30], Loss: 0.2211\n",
      "Validation Loss: 0.3043, Val_Accuracy: 88.37%\n",
      "Epoch [6/30], Loss: 0.1594\n",
      "Validation Loss: 0.2619, Val_Accuracy: 91.63%\n",
      "Epoch [7/30], Loss: 0.1259\n",
      "Validation Loss: 0.2943, Val_Accuracy: 91.40%\n",
      "Epoch [8/30], Loss: 0.0847\n",
      "Validation Loss: 0.3767, Val_Accuracy: 91.16%\n",
      "Epoch [9/30], Loss: 0.0893\n",
      "Validation Loss: 0.3494, Val_Accuracy: 91.40%\n",
      "Epoch [10/30], Loss: 0.0739\n",
      "Validation Loss: 0.3484, Val_Accuracy: 92.56%\n",
      "Epoch [11/30], Loss: 0.0421\n",
      "Validation Loss: 0.5786, Val_Accuracy: 92.56%\n",
      "Epoch [12/30], Loss: 0.0394\n",
      "Validation Loss: 0.5966, Val_Accuracy: 92.79%\n",
      "Epoch [13/30], Loss: 0.0319\n",
      "Validation Loss: 0.6209, Val_Accuracy: 92.56%\n",
      "Epoch [14/30], Loss: 0.0343\n",
      "Validation Loss: 0.6095, Val_Accuracy: 92.79%\n",
      "Epoch [15/30], Loss: 0.0302\n",
      "Validation Loss: 0.6097, Val_Accuracy: 92.79%\n",
      "Epoch [16/30], Loss: 0.0359\n",
      "Validation Loss: 0.6133, Val_Accuracy: 93.02%\n",
      "Epoch [17/30], Loss: 0.0283\n",
      "Validation Loss: 0.6156, Val_Accuracy: 92.79%\n",
      "Epoch [18/30], Loss: 0.0302\n",
      "Validation Loss: 0.6167, Val_Accuracy: 92.79%\n",
      "Epoch [19/30], Loss: 0.0310\n",
      "Validation Loss: 0.6168, Val_Accuracy: 92.79%\n",
      "Epoch [20/30], Loss: 0.0345\n",
      "Validation Loss: 0.6170, Val_Accuracy: 92.79%\n",
      "Epoch [21/30], Loss: 0.0341\n",
      "Validation Loss: 0.6177, Val_Accuracy: 92.79%\n",
      "Epoch [22/30], Loss: 0.0350\n",
      "Validation Loss: 0.6177, Val_Accuracy: 92.79%\n",
      "Epoch [23/30], Loss: 0.0275\n",
      "Validation Loss: 0.6182, Val_Accuracy: 92.79%\n",
      "Epoch [24/30], Loss: 0.0338\n",
      "Validation Loss: 0.6183, Val_Accuracy: 92.79%\n",
      "Epoch [25/30], Loss: 0.0268\n",
      "Validation Loss: 0.6186, Val_Accuracy: 92.79%\n",
      "Epoch [26/30], Loss: 0.0260\n",
      "Validation Loss: 0.6190, Val_Accuracy: 92.79%\n",
      "Epoch [27/30], Loss: 0.0373\n",
      "Validation Loss: 0.6195, Val_Accuracy: 92.79%\n",
      "Epoch [28/30], Loss: 0.0268\n",
      "Validation Loss: 0.6201, Val_Accuracy: 92.79%\n",
      "Epoch [29/30], Loss: 0.0277\n",
      "Validation Loss: 0.6205, Val_Accuracy: 92.79%\n",
      "Epoch [30/30], Loss: 0.0385\n",
      "Validation Loss: 0.6203, Val_Accuracy: 92.79%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()  #binary cross entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True, min_lr=1e-6)\n",
    "# chay them epoch\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device, dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad() #đặt lại gradient về 0\n",
    "        \n",
    "        outputs = model(inputs).squeeze() #squeeze() giảm một chiều của tensor\n",
    "        loss = criterion(outputs, labels) # tính loss\n",
    "        loss.backward() # tính gradient \n",
    "        optimizer.step() # cập nhật trọng số\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval() #đặt mô hình ở chế độ evaluation\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss/len(test_loader):.4f}, Val_Accuracy: {100 * correct / total:.2f}%\")\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "save_path = 'E:/Project/2024 Project/BrainTumor_Lam/models/brain_tumor_pytorch_v1.pth'\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9194805194805195\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        predicted = (outputs > 0.5).cpu().numpy().astype(int)\n",
    "        y_pred.extend(predicted)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
