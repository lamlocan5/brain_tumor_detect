{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.utils import normalize\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dir = os.listdir('./datasets/sort_crop_no/')\n",
    "yes_dir = os.listdir('./datasets/sort_crop_yes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,label = [],[]\n",
    "for i,cur_img_dir in enumerate(no_dir):\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./datasets/sort_crop_no/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        dataset.append(np.array(img))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,cur_img_dir in enumerate(yes_dir):\n",
    "    #check type of image\n",
    "    if cur_img_dir.split('.')[1]=='jpg':\n",
    "        img = cv2.imread('./datasets/sort_crop_yes/'+cur_img_dir)\n",
    "        img = Image.fromarray(img,'RGB')\n",
    "        img = img.resize((64,64))\n",
    "        dataset.append(np.array(img))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2152, 64, 64, 3)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2152,)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes observe:967, no observe:1185\n"
     ]
    }
   ],
   "source": [
    "print(f'yes observe:{sum(label)}, no observe:{len(label)-sum(label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and normalize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dataset)  \n",
    "label = np.array(label)  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.2 )        \n",
    "\n",
    "x_train = np.array(x_train, dtype=float)\n",
    "x_test= np.array(x_test, dtype=float)\n",
    "\n",
    "x_train_normalized=x_train/255\n",
    "x_test_normalized=x_test/255\n",
    "\n",
    "y_train=to_categorical(y_train, num_classes=2)\n",
    "y_test=to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1721, 64, 64, 3)\n",
      "Y train shape: (1721, 2)\n",
      "X test shape: (431, 64, 64, 3)\n",
      "Y test shape: (431, 2)\n",
      "X validation shape: (431, 64, 64, 3)\n",
      "Y validation shape: (431, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {x_train.shape}\\nY train shape: {y_train.shape}\\nX test shape: {x_test.shape}\\nY test shape: {y_test.shape}\\nX validation shape: {x_val.shape}\\nY validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNet, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def create_original_model():\n",
    "    model=load_model('Auto_Braintumor10EpochsCategorical.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try other network to choose the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_lenet5():\n",
    "    model = Sequential([\n",
    "        Conv2D(6, kernel_size=(5, 5), activation='sigmoid', input_shape=(INPUT_SIZE, INPUT_SIZE, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation='sigmoid'),\n",
    "        Dense(84, activation='sigmoid'),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_alexnet():\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=(INPUT_SIZE, INPUT_SIZE, 3)),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.02),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.02),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "def create_mobilenet():\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def compile_and_train(model, x_train_normalized, y_train, x_test_normalized, y_test):\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',  \n",
    "        optimizer='adam',  \n",
    "        metrics=['accuracy']  \n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  \n",
    "        patience=5,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',  \n",
    "        factor=0.1,  \n",
    "        patience=3,  \n",
    "        min_lr=1e-6  \n",
    "    )\n",
    "    \n",
    "\n",
    "    history = model.fit(\n",
    "        x_train_normalized, \n",
    "        y_train, \n",
    "        batch_size=16, \n",
    "        epochs=2,  \n",
    "        validation_data=(x_test_normalized, y_test),  \n",
    "        shuffle=True,  \n",
    "        callbacks=[early_stopping, reduce_lr]  \n",
    "    )\n",
    "\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test_normalized, y_test, verbose=1)\n",
    "\n",
    "    return accuracy, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13904\\1564747537.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('Original', create_original_model()),\n",
    "    ('LeNet-5', create_lenet5()),\n",
    "    ('AlexNet', create_alexnet()),\n",
    "    ('MobileNet', create_mobilenet()),\n",
    "]\n",
    "accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9656 - loss: 0.0913 - val_accuracy: 0.9304 - val_loss: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9687 - loss: 0.0727 - val_accuracy: 0.9722 - val_loss: 0.1001 - learning_rate: 0.0010\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.1093\n",
      "Epoch 1/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 0.7048 - val_accuracy: 0.5452 - val_loss: 0.6913 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 0.6880 - val_accuracy: 0.4548 - val_loss: 0.7026 - learning_rate: 0.0010\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5828 - loss: 0.6898 \n",
      "Epoch 1/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 290ms/step - accuracy: 0.5300 - loss: 1.0872 - val_accuracy: 0.5452 - val_loss: 0.6872 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 284ms/step - accuracy: 0.5711 - loss: 0.6799 - val_accuracy: 0.5452 - val_loss: 0.6842 - learning_rate: 0.0010\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5828 - loss: 0.6787\n",
      "Epoch 1/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 126ms/step - accuracy: 0.7395 - loss: 1.5993 - val_accuracy: 0.8190 - val_loss: 0.4440 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.9441 - loss: 0.1582 - val_accuracy: 0.8631 - val_loss: 0.6009 - learning_rate: 0.0010\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8370 - loss: 0.4258\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    accuracy = compile_and_train(model, x_train_normalized, y_train, x_test_normalized, y_test)\n",
    "    accuracies.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print accuracy of all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'History' and 'History'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[283], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Print models and their accuracies\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of models sorted by accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'History' and 'History'"
     ]
    }
   ],
   "source": [
    "accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "# Print models and their accuracies\n",
    "print(\"List of models sorted by accuracy:\")\n",
    "for name, accuracy in accuracies:\n",
    "    print(f'Model: {name}, Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "# Print the best model\n",
    "best_model_name, best_accuracy = accuracies[0]\n",
    "print(f'Best Model: {best_model_name}, Accuracy: {best_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, the original model is the best!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
